{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Customer Churn \n",
    "\n",
    "#### Author: Jacob Argue and John Cook\n",
    "#### Completed: December 2018\n",
    "#### Course: Business Econometrics II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Relevant Libararies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Train-test split library\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Basic libraries for graphs\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Libraries for decision boundary plots\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load customer churn data\n",
    "telco_df = pd.read_csv('data/Churn.csv')\n",
    "\n",
    "#Use dictionary to translate qualitative variables into dummies\n",
    "dmy_dict = {\"yes\":1, \"no\":0}\n",
    "churn_dict = {\"False.\":0, \"True.\":1}\n",
    "telco_df.Churn = telco_df.Churn.replace(churn_dict)\n",
    "telco_df.Intl_Plan = telco_df.Intl_Plan.replace(dmy_dict)\n",
    "telco_df.Vmail_Plan = telco_df.Vmail_Plan.replace(dmy_dict)\n",
    "\n",
    "#Declaring target and feature data\n",
    "target_df = telco_df.Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "telco_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert two-letter state codes into numbers\n",
    "state_dict = {\"AL\":0,\"AK\":1, \"AZ\":2, \"AR\":3, \"CA\":4, \"CO\":5, \"CT\":6, \"DE\":7, \"FL\":8, \"GA\":9, \"HI\":10, \"ID\":11, \"IL\":12, \"IN\":13, \"IA\":14, \"KS\":15, \"KY\":16, \"LA\":17, \"ME\":18, \"MD\":19, \"MA\":20, \"MI\":21, \"MN\":22, \"MS\":23, \"MO\":24, \"MT\":25, \"NE\":26, \"NV\":27, \"NH\":28, \"NJ\":29, \"NM\":30, \"NY\":31, \"NC\":32, \"ND\":33, \"OH\":34, \"OK\":35, \"OR\":36, \"PA\":37, \"RI\":38, \"SC\":39, \"SD\":40, \"TN\":41, \"TX\":42, \"UT\":43, \"VT\":44, \"VA\":45, \"WA\":46, \"WV\":47, \"WI\":48, \"WY\":49, \"DC\":50}\n",
    "telco_df.State = telco_df.State.replace(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change State column datatype from object to int\n",
    "telco_df['State'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dummy Variables for each State\n",
    "\n",
    "telco_df['AL'] = np.where(telco_df['State']!=0, 0, 1)\n",
    "telco_df['AK'] = np.where(telco_df['State']!=1, 0, 1)\n",
    "telco_df['AZ'] = np.where(telco_df['State']!=2, 0, 1)\n",
    "telco_df['AR'] = np.where(telco_df['State']!=3, 0, 1)\n",
    "telco_df['CA'] = np.where(telco_df['State']!=4, 0, 1)\n",
    "telco_df['CO'] = np.where(telco_df['State']!=5, 0, 1)\n",
    "telco_df['CT'] = np.where(telco_df['State']!=6, 0, 1)\n",
    "telco_df['DE'] = np.where(telco_df['State']!=7, 0, 1)\n",
    "telco_df['FL'] = np.where(telco_df['State']!=8, 0, 1)\n",
    "telco_df['GA'] = np.where(telco_df['State']!=9, 0, 1)\n",
    "telco_df['HI'] = np.where(telco_df['State']!=10, 0, 1)\n",
    "telco_df['ID'] = np.where(telco_df['State']!=11, 0, 1)\n",
    "telco_df['IL'] = np.where(telco_df['State']!=12, 0, 1)\n",
    "telco_df['IN'] = np.where(telco_df['State']!=13, 0, 1)\n",
    "telco_df['IA'] = np.where(telco_df['State']!=14, 0, 1)\n",
    "telco_df['KS'] = np.where(telco_df['State']!=15, 0, 1)\n",
    "telco_df['KY'] = np.where(telco_df['State']!=16, 0, 1)\n",
    "telco_df['LA'] = np.where(telco_df['State']!=17, 0, 1)\n",
    "telco_df['ME'] = np.where(telco_df['State']!=18, 0, 1)\n",
    "telco_df['MD'] = np.where(telco_df['State']!=19, 0, 1)\n",
    "telco_df['MA'] = np.where(telco_df['State']!=20, 0, 1)\n",
    "telco_df['MI'] = np.where(telco_df['State']!=21, 0, 1)\n",
    "telco_df['MN'] = np.where(telco_df['State']!=22, 0, 1)\n",
    "telco_df['MS'] = np.where(telco_df['State']!=23, 0, 1)\n",
    "telco_df['MO'] = np.where(telco_df['State']!=24, 0, 1)\n",
    "telco_df['MT'] = np.where(telco_df['State']!=25, 0, 1)\n",
    "telco_df['NE'] = np.where(telco_df['State']!=26, 0, 1)\n",
    "telco_df['NV'] = np.where(telco_df['State']!=27, 0, 1)\n",
    "telco_df['NH'] = np.where(telco_df['State']!=28, 0, 1)\n",
    "telco_df['NJ'] = np.where(telco_df['State']!=29, 0, 1)\n",
    "telco_df['NM'] = np.where(telco_df['State']!=30, 0, 1)\n",
    "telco_df['NY'] = np.where(telco_df['State']!=31, 0, 1)\n",
    "telco_df['NC'] = np.where(telco_df['State']!=32, 0, 1)\n",
    "telco_df['ND'] = np.where(telco_df['State']!=33, 0, 1)\n",
    "telco_df['OH'] = np.where(telco_df['State']!=34, 0, 1)\n",
    "telco_df['OK'] = np.where(telco_df['State']!=35, 0, 1)\n",
    "telco_df['OR'] = np.where(telco_df['State']!=36, 0, 1)\n",
    "telco_df['PA'] = np.where(telco_df['State']!=37, 0, 1)\n",
    "telco_df['RI'] = np.where(telco_df['State']!=38, 0, 1)\n",
    "telco_df['SC'] = np.where(telco_df['State']!=39, 0, 1)\n",
    "telco_df['SD'] = np.where(telco_df['State']!=40, 0, 1)\n",
    "telco_df['TN'] = np.where(telco_df['State']!=41, 0, 1)\n",
    "telco_df['TX'] = np.where(telco_df['State']!=42, 0, 1)\n",
    "telco_df['UT'] = np.where(telco_df['State']!=43, 0, 1)\n",
    "telco_df['VT'] = np.where(telco_df['State']!=44, 0, 1)\n",
    "telco_df['VA'] = np.where(telco_df['State']!=45, 0, 1)\n",
    "telco_df['WA'] = np.where(telco_df['State']!=46, 0, 1)\n",
    "telco_df['WV'] = np.where(telco_df['State']!=47, 0, 1)\n",
    "telco_df['WI'] = np.where(telco_df['State']!=48, 0, 1)\n",
    "telco_df['WY'] = np.where(telco_df['State']!=49, 0, 1)\n",
    "telco_df['DC'] = np.where(telco_df['State']!=50, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "telco_df.Area_Code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Area_Code_dict = {415:0, 408:1, 510:2}\n",
    "telco_df.Area_Code = telco_df.Area_Code.replace(Area_Code_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Area codes 415, 408, and 510 correspond to the Bay Area: San Francisco, San Jose, and Oakland, respectively.\n",
    "telco_df['SanFran'] = np.where(telco_df['Area_Code']!=0, 0, 1)\n",
    "telco_df['SanJose'] = np.where(telco_df['Area_Code']!=1, 0, 1)\n",
    "telco_df['Oakland'] = np.where(telco_df['Area_Code']!=2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop Phone as it only contains the last 7 digits, which are random and will only contribute noise; \n",
    "# Drop State as it has been reorganized into dummy variables for each State; \n",
    "# Drop Area_Code as it has been reorganized into dummy variables;\n",
    "# Drop Churn as it is the target variable and should stay separate from feature variables.\n",
    "features_df = telco_df.drop(['Phone', 'State', 'Area_Code', 'Churn'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df = telco_df['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading train-test split library\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Conducting train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_df, target_df, test_size=0.33, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading Cross-validation and Hyperparameter optimization libraries\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "#Step 1: Define the algorithm\n",
    "logitC = linear_model.LogisticRegression()\n",
    "\n",
    "#Step 2: Fit the model\n",
    "logit_fit0 = logitC.fit(X_train, y_train)\n",
    "\n",
    "#(Step 2A: Display details parameters used for the estimation)\n",
    "print(logit_fit0)\n",
    "\n",
    "#Step 3: \n",
    "y_score_logit = logit_fit0.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set k fold parameters, including number of k folds and randomization\n",
    "crossv = KFold(n_splits=3, shuffle=True, random_state=4973)\n",
    "\n",
    "#Set model to be trained and cross validated\n",
    "Lasso_mod = linear_model.Lasso()\n",
    "\n",
    "#Calculate scores for lasso\n",
    "cv_scores = cross_val_score(Lasso_mod, features_df, churn_df, cv = crossv, scoring='r2')\n",
    "\n",
    "print('LASSO parameters', Lasso_mod)\n",
    "print('R-sq for each fold are:', cv_scores)\n",
    "print('Average R-sq, across folds:', np.mean(cv_scores))\n",
    "print('Std R-sq, across folds:', np.std(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the grid of possible parameter values for alpha\n",
    "alpha_range = np.linspace(0.001, 10, 100)\n",
    "\n",
    "#Defining grid search\n",
    "gscv_model = GridSearchCV(Lasso_mod, dict(alpha=alpha_range), cv=3, refit=True, scoring='r2')\n",
    "gscv_result = gscv_model.fit(X_train, y_train)\n",
    "\n",
    "#Report results\n",
    "print(gscv_result.best_estimator_)\n",
    "print('The optimal penalty parameter is:', gscv_result.best_params_)\n",
    "print('Cross-validated R-squared:', gscv_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_scores, test_scores = validation_curve(Lasso_mod, features_df, churn_df, param_range=alpha_range, param_name=\"alpha\", cv=3, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outcomes of interest\n",
    "mean_test = np.mean(test_scores, axis=1)\n",
    "\n",
    "#plot\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(alpha_range, mean_test, 'o-', label=\"Cross-validation\")\n",
    "plt.grid()\n",
    "plt.xlabel('Value for alpha')\n",
    "plt.ylabel('Mean test R-squared')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This essentially shows that an alpha value of '0', or non-regularized lasso, is the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing ROC and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "#Calculate False-Positive and True Positive Rates\n",
    "fpr_logit, tpr_logit, _ = roc_curve(y_test, y_score_logit[:,1])\n",
    "\n",
    "#AUC\n",
    "roc_auc_logit = auc(fpr_logit, tpr_logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max Depth optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_depths = np.linspace(1, 20, 20, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for max_depth in max_depths:\n",
    "   dt = DecisionTreeClassifier(max_depth=max_depth)\n",
    "   dt.fit(X_train, y_train)\n",
    "   train_pred = dt.predict(X_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   # Add auc score to previous train results\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = dt.predict(X_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   # Add auc score to previous test results\n",
    "   test_results.append(roc_auc)\n",
    "\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(max_depths, train_results, color='blue', label='Train AUC')\n",
    "line2, = plt.plot(max_depths, test_results, color='red', label='Test AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('Tree depth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ideal tree depth appears to be 5. After that point there is overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_samples_split optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_splits = np.linspace(0.01, 0.2, 20, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for min_samples_split in min_samples_splits:\n",
    "   dt = DecisionTreeClassifier(min_samples_split=min_samples_split)\n",
    "   dt.fit(X_train, y_train)\n",
    "   train_pred = dt.predict(X_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds =    roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = dt.predict(X_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(min_samples_splits, train_results, 'B', label='Train AUC')\n",
    "line2, = plt.plot(min_samples_splits, test_results, 'R', label='Test AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('min samples split')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ideal minimum percentage of the sample that should be considered is .7%; less than this and there is overfitting, and more than this there is a rapid decline in AUC accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Decision Tree with optimized values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Define the algorithm\n",
    "dt1 = tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth= 5, min_samples_split=.07)\n",
    "\n",
    "#Step 2: Fit the model\n",
    "dt_fit1 = dt1.fit(X_train, y_train)\n",
    "\n",
    "#(Step 2A: Display details parameters used for the estimation)\n",
    "print(dt_fit1)\n",
    "\n",
    "#Step 3: \n",
    "y_score_dtc = dt_fit1.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Define the algorithm\n",
    "dtc0 = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "\n",
    "#Step 2: Fit the model\n",
    "dtc_fit0 = dtc0.fit(X_train, y_train)\n",
    "\n",
    "#(Step 2A: Display details parameters used for the estimation)\n",
    "print(dtc_fit0)\n",
    "\n",
    "#Step 3: \n",
    "y_score_dtc = dtc_fit0.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(dt1, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing ROC and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculate False-Positive and True Positive Rates\n",
    "fpr_dtc, tpr_dtc, _ = roc_curve(y_test, y_score_dtc[:,1])\n",
    "\n",
    "#AUC\n",
    "roc_auc_dtc = auc(fpr_dtc, tpr_dtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: designate algorithm\n",
    "bagc0 = ensemble.BaggingClassifier(random_state=42)\n",
    "\n",
    "#Step 2: fit model on training data\n",
    "bagc_fit0 = bagc0.fit(X_train, y_train)\n",
    "\n",
    "#Step 2A: display parameters used\n",
    "print(bagc_fit0)\n",
    "\n",
    "#Step 3: \n",
    "y_score_bagc = bagc_fit0.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy for Bagging Classifier', bagc_fit0.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred0 = bagc_fit0.predict(X_test)\n",
    "cmatrix0 = confusion_matrix(y_test, y_pred0)\n",
    "df_cm = pd.DataFrame(cmatrix0, index=['Churn (true)', 'Stay (true)'], columns=['Churn (pred)', 'Stay (pred)'])\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set k fold parameters, including number of k folds and randomization\n",
    "crossv = KFold(n_splits=10, shuffle=True, random_state=4973)\n",
    "\n",
    "#Calculate scores for decision tree\n",
    "cv_scores = cross_val_score(bagc0, features_df, target_df,cv = crossv, scoring='accuracy')\n",
    "\n",
    "print('Decision Tree parameters', bagc0)\n",
    "print('Accuracy for each fold are:', cv_scores)\n",
    "print('Average accuracy, across folds:', np.mean(cv_scores))\n",
    "print('Std accuracy, across folds:', np.std(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing ROC and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculate False-Positive and True Positive Rates\n",
    "fpr_bagc, tpr_bagc, _ = roc_curve(y_test, y_score_bagc[:,1])\n",
    "\n",
    "#AUC\n",
    "roc_auc_bagc = auc(fpr_bagc, tpr_bagc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Step 1: designate algorithm\n",
    "rfc0 = ensemble.RandomForestClassifier(random_state=23, criterion='entropy')\n",
    "\n",
    "#Step 2: fit model on training data\n",
    "rfc_fit0 = rfc0.fit(X_train, y_train)\n",
    "\n",
    "#Step 2A: display parameters used\n",
    "print(rfc_fit0)\n",
    "\n",
    "#Step 3: \n",
    "y_score_rfc = rfc_fit0.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing ROC and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculate False-Positive and True Positive Rates\n",
    "fpr_rfc, tpr_rfc, _ = roc_curve(y_test, y_score_rfc[:,1])\n",
    "\n",
    "#AUC\n",
    "roc_auc_rfc = auc(fpr_rfc, tpr_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbor Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "#Step 1: designate algorithm\n",
    "kNNc0 = neighbors.KNeighborsClassifier(weights='uniform', algorithm='brute', p=2)\n",
    "\n",
    "#Step 2: fit model on training data\n",
    "kNNc_fit0 = kNNc0.fit(X_train, y_train)\n",
    "\n",
    "#Step 2A: display parameters used\n",
    "print(kNNc_fit0)\n",
    "\n",
    "#Step 3: \n",
    "y_score_kNNc = kNNc_fit0.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy for kNN Classifier', kNNc_fit0.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred0 = kNNc_fit0.predict(X_test)\n",
    "cmatrix0 = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(cmatrix0, index=['Churn (true)', 'Stay (true)'], columns=['Churn (pred)', 'Stay (pred)'])\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set k fold parameters, including number of k folds and randomization\n",
    "crossv = KFold(n_splits=10, shuffle=True, random_state=23)\n",
    "\n",
    "#Calculate scores for decision tree\n",
    "cv_scores = cross_val_score(kNNc0, features_df, target_df,cv = crossv, scoring='accuracy')\n",
    "\n",
    "print('Decision Tree parameters', kNNc0)\n",
    "print('Accuracy for each fold are:', cv_scores)\n",
    "print('Average accuracy, across folds:', np.mean(cv_scores))\n",
    "print('Std accuracy, across folds:', np.std(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing ROC and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculate False-Positive and True Positive Rates\n",
    "fpr_kNNc, tpr_kNNc, _ = roc_curve(y_test, y_score_kNNc[:,1])\n",
    "\n",
    "#AUC\n",
    "roc_auc_kNNc = auc(fpr_kNNc, tpr_kNNc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparing the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reciever Operating Characteristic (ROC) Curves is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr_logit, tpr_logit, color='darkorange',lw=2 ,label='Ridge-Logit (AUC = %0.2f)' % roc_auc_logit)\n",
    "plt.plot(fpr_dtc, tpr_dtc, color='darkred',lw=2 ,label='Decision Tree (AUC = %0.2f)' % roc_auc_dtc)\n",
    "plt.plot(fpr_kNNc, tpr_kNNc, color='red',lw=2 ,label='kNN (AUC = %0.2f)' % roc_auc_kNNc)\n",
    "plt.plot(fpr_bagc, tpr_bagc, color='green',lw=2 ,label='Bagged (AUC = %0.2f)' % roc_auc_bagc)\n",
    "plt.plot(fpr_rfc, tpr_rfc, color='blue',lw=2 ,label='Random Forest (AUC = %0.2f)' % roc_auc_rfc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_cumulative_gain(y_test, y_score_logit)\n",
    "plt.title('Cumulative Response Curve Ridge-Logit')\n",
    "plt.show()\n",
    "\n",
    "skplt.metrics.plot_cumulative_gain(y_test, y_score_dtc)\n",
    "plt.title('Cumulative Response Curve Decision Tree')\n",
    "plt.show()\n",
    "\n",
    "skplt.metrics.plot_cumulative_gain(y_test, y_score_kNNc)\n",
    "plt.title('Cumulative Response Curve kNN Classifier')\n",
    "plt.show()\n",
    "\n",
    "skplt.metrics.plot_cumulative_gain(y_test, y_score_bagc)\n",
    "plt.title('Cumulative Response Curve Bagging Classfier')\n",
    "plt.show()\n",
    "\n",
    "skplt.metrics.plot_cumulative_gain(y_test, y_score_rfc)\n",
    "plt.title('Cumulative Response Curve Random Forest Classfier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_lift_curve(y_test, y_score_logit)\n",
    "plt.title('Lift Curve Ridge-Logit')\n",
    "plt.show()\n",
    "\n",
    "skplt.metrics.plot_lift_curve(y_test, y_score_dtc)\n",
    "plt.title('Lift Curve Decision Tree')\n",
    "plt.show()\n",
    "\n",
    "skplt.metrics.plot_lift_curve(y_test, y_score_kNNc)\n",
    "plt.title('Lift Curve kNN Classifier')\n",
    "plt.show()\n",
    "\n",
    "skplt.metrics.plot_lift_curve(y_test, y_score_bagc)\n",
    "plt.title('Lift Curve Bagging Classfier')\n",
    "plt.show()\n",
    "\n",
    "skplt.metrics.plot_lift_curve(y_test, y_score_rfc)\n",
    "plt.title('Lift Curve Random Forest Classfier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Profit Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lifetime value of a Verizon customer in 2005 (the most recent date data is available) is $2,589. Due to inflation and growth, I will round that to $3,000. \n",
    "\n",
    "True Positives we predict to churn and they do churn; True Negatives we predict to stay and they stay.\n",
    "False Positives we predict to churn and they stay; False Negatives we predict to stay and they churn.\n",
    "\n",
    "The profit impact of prediction varies by which area in the confusion matrix a given observation is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def standard_confusion_matrix(y_true, y_pred):\n",
    "    #Reformat confusion matrix output from sklearn for plotting profit curve.\n",
    "    [[tn, fp], [fn, tp]] = confusion_matrix(y_true, y_pred)\n",
    "    return np.array([[tp, fp], [fn, tn]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profit Cost-Benefit Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cost-benefit matrix with best guesses\n",
    "profit_TP = 500 # I assume that of the customers who are predicted to churn, we can get one-sixth of them to stay through targeted promotions, etc.\n",
    "profit_FP = -300 # The cost of giving customers who were going to stay anyway 10% discount, for example\n",
    "profit_FN = -3000 # The customers we thought would stay but did not: negative lifetime value of a customer\n",
    "profit_TN = 3000 # Lifetime value of a customer\n",
    "\n",
    "costbenefit_mat = np.array([[profit_TP, profit_FP],\n",
    "                            [profit_FN, profit_TN]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_profit_curve(model_label, costbenefit_mat, y_proba, y_test, col):\n",
    "    '''\n",
    "    Plot profit curve.\n",
    "    \n",
    "    INPUTS:\n",
    "    - model label\n",
    "    - cost benefit matrix in the same format as the confusion matrix\n",
    "    - predicted probabilities on test data\n",
    "    - actual test data\n",
    "    - colors\n",
    "    ''' \n",
    "\n",
    "    # Profit curve data\n",
    "    profits = [] # one profit value for each T (threshold)\n",
    "    thresholds = sorted(y_proba, reverse=True)\n",
    "    \n",
    "    # For each threshold, calculate profit - starting with largest threshold\n",
    "    for T in thresholds:\n",
    "        y_pred = (y_proba > T).astype(int)\n",
    "        confusion_mat = standard_confusion_matrix(y_test, y_pred)\n",
    "        # Calculate total profit for this threshold\n",
    "        profit = sum(sum(confusion_mat * costbenefit_mat)) / len(y_test)\n",
    "        profits.append(profit)    \n",
    "    \n",
    "    # Profit curve plot\n",
    "    max_profit = round(max(profits), 2)\n",
    "    plt.plot(np.linspace(0, 1, len(y_test)), profits, color=col, linewidth=3, label = '{}, max profit ${} per customer'.format(model_label, max_profit))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = [logitC, dt, kNNc0, bagc0, rfc0]\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "# fig.set_facecolor('#F2F2F2')\n",
    "colors = ['r', 'g', 'b', 'm', 'darkorange']\n",
    "for i, model in enumerate(models):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_score = model.predict_proba(X_test)[:,1]\n",
    "    plot_profit_curve(model.__class__.__name__, costbenefit_mat, y_score, y_test, colors[i])\n",
    "\n",
    "plt.title(\"Profit Curves\")\n",
    "plt.xlabel(\"Percentage of test customers (decreasing by score)\")\n",
    "plt.ylabel(\"Profit\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('Profit_curve.png', facecolor=fig.get_facecolor())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know that the Bagging Classifier is the best algorithm for this dataset, let's see how total profitability is affected. At the maximum, profit per customer is 2417.45 and if we were to expand this to the entire dataset of 3333 customers, this results in 8,056,694.25 more profit. This is as compared with 7,836,182.97 for Random Forest, 7,498,050.12 for Decision Tree, 7,125,354.06 for K-Nearest Neighbors, and 7,045,962.00 for Logistic Regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
